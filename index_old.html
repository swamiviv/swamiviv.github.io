<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Swami Sankaranarayanan</title>
  <meta name="author" content="Swami Sankaranarayanan">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/seal_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Swami Sankaranarayanan</name>
              </p>
              <p>
                I am a Postdoctoral Associate at <a href="https://www.mit.edu">MIT</a> working with
                <a href="https://www.web.mit.edu/phillipi">Phillip Isola</a> and
                <a href="https://healthyml.org/">Marzyeh Ghassemi</a>.
              </p>
              <p>
                Previously, I was a Research Scientist at <a href="https:www.butterflynetwork.com">Butterfly Network</a> where I was part
                of the deep learning team led by <a href="https://cs.nyu.edu/~silberman/">Nathan Silberman</a>. My responsibilities included
                developing and deploying interpretable machine learning models for realtime ultrasound scanning. I was an integral
                part of the team that developed the ML-based
                <a href="https://twitter.com/ButterflyNetInc/status/1275827731138252801?s=20">Auto
                  Bladder Volume tool</a>, among others.
              </p>
              <p>
                I obtained my Ph.D under <a href="https://www.bme.jhu.edu/faculty_staff/rama-chellappa-phd/">Prof. Rama Chellappa</a>,
                for which I was awarded the <a href="https://ece.umd.edu/news/story/ece-names-20172018-distinguished-dissertation-fellows">
                ECE Distinguished Dissertation Award</a>.

                In my research, I have explored different aspects of deep learning representations
                from the point of  view of robustness and invariance. I have worked on several topics
                such as Semantic Segmentation, Domain Adaptation, Adversarial learning, Multi task
                learning and Facial recognition systems.
              </p>
              <p>
                Broadly, my objective is to develop automated agents that mimic human intelligence
                not only in their ability to perceive known aspects of their environment but also
                embody the traits of uncertainty and causality. As machine learning algorithms become
                commonplace in safety critical systems such as in <a href="https://www.scientificamerican.com/article/how-artificial-intelligence-will-change-medicine/">healthcare</a> and
                <a href="https://blogs.scientificamerican.com/voices/how-to-fight-bias-with-predictive-policing/">law enforcement </a>,
                there is a growing need for socially intelligent agents as well as informed regulation.
              </p>
              <p style="text-align:center">
                <a href="mailto:swamiviv@mit.edu">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?user=w3KgvQIAAAAJ&hl=en&oi=ao">Google Scholar</a> &nbsp/&nbsp
                <a href="https://twitter.com/swamiviv1">Twitter</a> &nbsp/&nbsp
                <a href="https://github.com/swamiviv">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/display_pic_bigbend.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/display_pic_bigbend.jpg" class="hoverZoomLink"></a>
            </td>
          </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Select Papers </heading>
            </td>
          </tr>
          </tbody></table>
          <!--Paper start: annotator_confusion-->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='annotator_confusion_image'>
                  <img src='images/annotator_confusion.png' width="160"></div>
              </div>
            </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Learning From Noisy Labels By Regularized Estimation Of Annotator Confusion</papertitle>
                <br>
                <a href="https://rt416.github.io/">Ryutaro Tanno</a>,
                <a href="https://scholar.google.com/citations?user=sNMowOIAAAAJ&hl=en"> Ardavan Saeedi</a>,
                <strong>Swami Sankaranarayanan</strong>,
                <a href="http://www0.cs.ucl.ac.uk/people/D.Alexander.html">Daniel Alexander</a>,
                <a href="https://cs.nyu.edu/~silberman/">Nathan Silberman</a>,
                <br>
                <em>CVPR</em>, 2019
                <br>
                <a href="https://arxiv.org/abs/1902.03680">arXiv</a> /
                <a href="https://rt416.github.io/pdf/trace_codes.pdf">code</a>
                <p></p>
                <p>In addition to improving accuracy, we estimate annotator skill levels and biases.</p>
              </td>
            </tr>
          </tbody></table>
          <!--Paper end: annotator_confusion-->
          <!--Paper start: Metareg-->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr onmouseout="metareg_stop()" onmouseover="metareg_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='metareg_image'>
                  <img src='images/metareg_after.png' width="180"></div>
                <img src='images/metareg_before.png' width="180">
              </div>
              <script type="text/javascript">
                function metareg_start() {
                  document.getElementById('metareg_image').style.opacity = "1";
                }
                function metareg_stop() {
                  document.getElementById('metareg_image').style.opacity = "0";
                }
                metareg_stop()
              </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>MetaReg: Towards Domain Generalization using Meta-Regularization</papertitle>
                <br>
                 <a href="https://www.cs.umd.edu/~yogesh/">Yogesh Balaji</a>,
                <strong>Swami Sankaranarayanan*</strong>,
                <a href="https://www.bme.jhu.edu/faculty_staff/rama-chellappa-phd/">Rama Chellappa</a>,
                <br>
                <em>NeurIPS</em>, 2018
                <br>
                <a href="https://papers.nips.cc/paper/7378-metareg-towards-domain-generalization-using-meta-regularization.pdf">pdf</a> /
                <a href="https://github.com/yogeshbalaji/Meta-Learning-Domain-Generalization">code</a>
                <p></p>
                <p>Learning representations that generalize to unseen domains by regularizing the structure of the neural network.</p>
              </td>
            </tr>
          </tbody></table>
          <!--Paper end: Metareg-->
          <!--Paper start: LSD-->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr onmouseout="lsd_stop()" onmouseover="lsd_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='lsd_image'>
                  <img src='images/lsd_after.png' height=120 width="180"></div>
                <img src='images/lsd_before.png' height=120 width="180">
              </div>
              <script type="text/javascript">
                function lsd_start() {
                  document.getElementById('lsd_image').style.opacity = "1";
                }

                function lsd_stop() {
                  document.getElementById('lsd_image').style.opacity = "0";
                }
                lsd_stop()
              </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Learning from Synthetic Data (LSD): Addressing Domain Shift for Semantic Segmentation</papertitle>
                <br>
                <strong>Swami Sankaranarayanan*</strong>,
                <a href="https://www.cs.umd.edu/~yogesh/">Yogesh Balaji*</a>,
                <a href="https://www.linkedin.com/in/arpit-jain-4a89b31a/de?challengeId=AQEIOdw-VmzZhwAAAXUVBAyJ_TQ-ajzhRkoPN-s6qOgDwjxGgqc-aEtfPsEe_T_D4psOuZJShkxoQhHpOxXM9OS0xdvtL4Ev7Q&submissionId=05a021f2-ecc7-3c16-a059-f5ab9b2f5636"> Arpit Jain</a>,
                <a href="https://ai.facebook.com/people/ser-nam-lim/">Ser Nam Lim</a>,
                <a href="https://www.bme.jhu.edu/faculty_staff/rama-chellappa-phd/">Rama Chellappa</a>,
                <br>
                <em>CVPR</em>, 2018 &nbsp <font color=#FF8080><strong>(Spotlight)</strong></font>
                <br>
                <a href="https://arxiv.org/abs/1711.06969">arXiv</a> /
                <a href="https://github.com/swamiviv/LSD-seg">code</a>
                <p></p>
                <p>Using GANs to model domain shift for structured prediction problems.</p>
              </td>
            </tr>
          </tbody></table>
          <!--Paper end: LSD-->
          <!--Paper start: GTA-->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr onmouseout="gta_stop()" onmouseover="gta_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='gta_image'>
                  <img src='images/gta_after.png' width="160"></div>
                <img src='images/gta_before.png' width="160">
              </div>
              <script type="text/javascript">
                function gta_start() {
                  document.getElementById('gta_image').style.opacity = "1";
                }

                function gta_stop() {
                  document.getElementById('gta_image').style.opacity = "0";
                }
                gta_stop()
              </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Generate To Adapt (GTA): Aligning Domains using Generative Adversarial Networks</papertitle>
                <br>
                <strong>Swami Sankaranarayanan*</strong>,
                <a href="https://www.cs.umd.edu/~yogesh/">Yogesh Balaji*</a>,
                <a href="https://engineering.jhu.edu/ece/faculty/carlos-castillo/">Carlos Castillo</a>,
                <a href="https://www.bme.jhu.edu/faculty_staff/rama-chellappa-phd/">Rama Chellappa</a>,
                <br>
                <em>CVPR</em>, 2018 &nbsp <font color=#FF8080><strong>(Spotlight)</strong></font>
                <br>
                <a href="https://arxiv.org/abs/1704.01705">arXiv</a> /
                <a href="https://github.com/yogeshbalaji/Generate_To_Adapt">code</a>
                <p></p>
                <p>Using GANs to model domain shift for image classification problems.</p>
              </td>
            </tr>
          </tbody></table>
          <!--Paper end: GTA-->
          <!--Paper start: PNAS_Face-->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr onmouseout="pnas_face_stop()" onmouseover="pnas_face_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='pnas_face_image'>
                  <img src='images/pnas_face_after.png' height=140 width="160"></div>
                <img src='images/pnas_face_before.png' width="160">
              </div>
              <script type="text/javascript">
                function pnas_face_start() {
                  document.getElementById('pnas_face_image').style.opacity = "1";
                }

                function pnas_face_stop() {
                  document.getElementById('pnas_face_image').style.opacity = "0";
                }
                pnas_face_stop()
              </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Face recognition accuracy of forensic examiners, superrecognizers, and face recognition algorithms</papertitle>
                <br>
                Jonathon Phillips,
                Amy Yates,
                Ying Hu,
                Carina Hahn,
                Eilidh Noyes,
                Kelsey Jackson,
                Jacqueline Cavazos,
                Geraldine Jeckeln,
                Rajeev Ranjan,
                <strong>Swami Sankaranarayanan</strong>,
                Jun-Cheng Chen,
                <a href="https://engineering.jhu.edu/ece/faculty/carlos-castillo/">Carlos Castillo</a>,
                <a href="https://www.bme.jhu.edu/faculty_staff/rama-chellappa-phd/">Rama Chellappa</a>,
                David White,
                Alice J. O’Toole
                <p>
                <em>Proceedings of National Academy of Sciences (PNAS) </em>, 2018
                </p>
                <a href="https://www.pnas.org/content/115/24/6171">Paper</a>
                <p>Pairing automated face recognition systems with human experts on recognizing faces in the context of law enforcement.</p>
              </td>
            </tr>
          </tbody></table>
          <!--Paper end: PNAS_face-->
          <!--Paper start: AAAI_reg-->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='aaai_reg_image'>
                  <img src='images/aaai_reg_before.png' width="160"></div>
              </div>
            </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Regularizing deep networks using efficient layerwise adversarial training</papertitle>
                <br>
                <strong>Swami Sankaranarayanan</strong>,
                <a href="https://www.linkedin.com/in/arpit-jain-4a89b31a/de?challengeId=AQEIOdw-VmzZhwAAAXUVBAyJ_TQ-ajzhRkoPN-s6qOgDwjxGgqc-aEtfPsEe_T_D4psOuZJShkxoQhHpOxXM9OS0xdvtL4Ev7Q&submissionId=05a021f2-ecc7-3c16-a059-f5ab9b2f5636"> Arpit Jain</a>,
                <a href="https://www.bme.jhu.edu/faculty_staff/rama-chellappa-phd/">Rama Chellappa</a>,
                <a href="https://ai.facebook.com/people/ser-nam-lim/">Ser Nam Lim</a>,
                <br>
                <em>AAAI</em>, 2018
                <br>
                <a href="https://arxiv.org/abs/1705.07819">arXiv</a>
                <p>Exploring adversarial robustness v accuracy tradeoff by introducing regularization in the intermediate layers of a DNN.</p>
              </td>
            </tr>
          </tbody></table>
          <!--Paper end: AAAI_reg-->
          <!--Paper start: GP-->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr onmouseout="gp_stop()" onmouseover="gp_start()">
              <td style="padding:20px;width:25%;vertical-align:text-bottom">
              <div class="one">
                <div class="two" id='gp_image'>
                  <img src='images/gp_after.png' width="160"></div>
                <img src='images/gp_before.png' width="160">
              </div>
              <script type="text/javascript">
                function gp_start() {
                  document.getElementById('gp_image').style.opacity = "1";
                }

                function gp_stop() {
                  document.getElementById('gp_image').style.opacity = "0";
                }
                gp_stop()
              </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Guided Perturbations: Self Corrective Behavior in Convolutional Neural Networks</papertitle>
                <br>
                <strong>Swami Sankaranarayanan</strong>,
                <a href="https://www.linkedin.com/in/arpit-jain-4a89b31a/de?challengeId=AQEIOdw-VmzZhwAAAXUVBAyJ_TQ-ajzhRkoPN-s6qOgDwjxGgqc-aEtfPsEe_T_D4psOuZJShkxoQhHpOxXM9OS0xdvtL4Ev7Q&submissionId=05a021f2-ecc7-3c16-a059-f5ab9b2f5636"> Arpit Jain</a>,
                <a href="https://ai.facebook.com/people/ser-nam-lim/">Ser Nam Lim</a>,
                <br>
                <em>ICCV</em>, 2017
                <br>
                <a href="https://arxiv.org/abs/1703.07928">arXiv</a>
                <p>Adversarial and non-adversarial perturbation analysis of DNN based semantic segmentation methods.</p>
              </td>
            </tr>
          </tbody></table>
          <!--Paper end: GP-->
          <!--Paper start: TPE-->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <td style="padding:20px;width:25%;vertical-align:middle">
              <div class="one">
                <div class="two" id='tpe_image'>
                  <img src='images/tpe.png' width="160"></div>
              </div>
            </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <papertitle>Triplet probabilistic embedding for face verification and clustering</papertitle>
                <br>
                <strong>Swami Sankaranarayanan*</strong>,
                <a href="https://scholar.google.com.au/citations?user=DfcWwgcAAAAJ&hl=en">Azadeh Alavi</a>,
                <a href="https://engineering.jhu.edu/ece/faculty/carlos-castillo/">Carlos Castillo</a>,
                <a href="https://www.bme.jhu.edu/faculty_staff/rama-chellappa-phd/">Rama Chellappa</a>,
                <br>
                <em>BTAS</em>, 2016 &nbsp <font color=#FF8080><strong>(NVIDIA Award for Best Paper)</strong></font> <font color=#FF8080><strong>(IJCB Five Year Impact Award)</strong></font>
                <br>
                <a href="https://arxiv.org/abs/1604.05417">arXiv</a> /
                <a href="https://github.com/meownoid/face-identification-tpe">third party implementation</a>
                <p>Efficient dimensionality reduction for large scale unconstrained face recognition.</p>
              </td>
            </tr>
          </tbody></table>
          <!--Paper end: LSD-->
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:center;font-size:small;">
                Page design borrowed from <a href="https://jonbarron.info/">Jon Barron</a>
              </p>
              <div style="text-align: center">
              <a href="https://accessibility.mit.edu/">Accessibility</a>
              </div>
            </td>
          </tr>
        </tbody></table>
  </table>
</body>
</html>
